{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning and statistical learning\n",
    "\n",
    "## Pictures: Parkinson’s Disease\n",
    "\n",
    "This hands-on session focuses on pictures. The objective is to manipulate images to perform classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task consists in detecting Parkinson's disease from hand-drawn images of spirals and waves. This application is inspired by [Adrian Rosebrock's tutorial](https://www.pyimagesearch.com/2019/04/29/detecting-parkinsons-disease-with-opencv-computer-vision-and-the-spiral-wave-test/). \n",
    "\n",
    "\n",
    "The idea is to compare spiral or wave images drawn by patients with Parkinson's disease or by patients without it. Patients with Parkinson's disease, as shown in [Zham _et al_. (2017)](https://doi.org/10.3389%2Ffneur.2017.00435), draw less quickly and with less pressure than other test subjects. In the tutorial, Adrian Rosebrock mentions that João Paulo Folador, a Brazilian Ph.D. student explored the following idea: maybe it is possible to detect Parkinson's disease from the sole images, without measuring speed and pressure of the pen on paper.\n",
    "\n",
    "you will **train a classifier** to automatically detect whether a patient is suffering from Parkinson's disease.\n",
    "\n",
    "To that end, you have a set of image data organized as follows:\n",
    "\n",
    "- Spiral data:\n",
    "\n",
    "    - training set: 36 healthy and 36 Parkinson (n=72)\n",
    "    - testing set: 15 healthy and 15 Parkinson (n=30)\n",
    "- Wave data:\n",
    "\n",
    "    - training set: 36 healthy and 36 Parkinson (n=72)\n",
    "    - testing set: 15 healthy and 15 Parkinson (n=30).\n",
    "\n",
    "You will adopt the following strategy:\n",
    "\n",
    "- load the images into python\n",
    "- convert them in greyscale\n",
    "- crop them\n",
    "- create a matrix where each column represents an example (i.e., an individual) and each line the value of a pixel\n",
    "- perform a principal component analysis\n",
    "- use a subset of the principal components to train a classifier\n",
    "- test the performance of the model on a test sample\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Loading images\n",
    "\n",
    "The hand-drawings of the subjects are provided as PNG files, according to the following tree structure (you will focus on the spiral test only):\n",
    "\n",
    "```\n",
    "pictures\n",
    "├── donnees\n",
    "│   └── dataset-parkinson\n",
    "│       └── spiral\n",
    "│           └── testing\n",
    "│           │   └── healthy\n",
    "│           │   │   └── V01HE01.png\n",
    "│           │   │   └── ...\n",
    "│           │   │   └── V55HE15.png\n",
    "│           │   └── parkinson\n",
    "│           │   │   └── V01PE01.png\n",
    "│           │   │   └── ...\n",
    "│           │   │   └── V15PE015.png\n",
    "│           └── training\n",
    "│           │   └── healthy\n",
    "│           │   │   └── V01HE02.png\n",
    "│           │   │   └── ...\n",
    "│           │   │   └── V55HE11.png\n",
    "│           │   └── parkinson\n",
    "│           │   │   └── V01PE02.png\n",
    "│           │   │   └── ...\n",
    "│           │   │   └── V15PE03.png\n",
    "```\n",
    "\n",
    "The file names can be used to determine whether or not the individual has Parkinson's disease (P for Parkinson's or H for Healthy). The data are already split into a training and a testing sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us list all the files, using the `listdir()` function from {`os`}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_train_healthy = \"/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset/spiral/training/healthy\"\n",
    "N_train_healthy = os.listdir(path_train_healthy)\n",
    "\n",
    "path_train_parkinson = \"/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset/spiral/training/parkinson\"\n",
    "N_train_parkinson = os.listdir(path_train_parkinson)\n",
    "\n",
    "path_test_healthy = \"/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset/spiral/testing/healthy\"\n",
    "N_test_healthy = os.listdir(path_test_healthy)\n",
    "\n",
    "path_test_parkinson = \"/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset/spiral/testing/parkinson\"\n",
    "N_test_parkinson = os.listdir(path_test_parkinson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [[path_train_healthy,   N_train_healthy],\n",
    "     [path_train_parkinson, N_train_parkinson],\n",
    "     [path_test_healthy,    N_test_healthy],\n",
    "     [path_test_parkinson,  N_test_parkinson]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset-parkinson/spiral/training/healthy',\n",
       "  ['V09HE02.png',\n",
       "   'V55HE06.png',\n",
       "   'V55HE07.png',\n",
       "   'V09HE03.png',\n",
       "   'V55HE11.png',\n",
       "   'V55HE05.png',\n",
       "   'V10HE02.png',\n",
       "   'V10HE03.png',\n",
       "   'V55HE04.png',\n",
       "   'V55HE10.png',\n",
       "   'V01HE02.png',\n",
       "   'V11HE02.png',\n",
       "   'V11HE03.png',\n",
       "   'V01HE03.png',\n",
       "   'V55HE01.png',\n",
       "   'V08HE02.png',\n",
       "   'V55HE03.png',\n",
       "   'V55HE02.png',\n",
       "   'V08HE03.png',\n",
       "   'V12HE01.png',\n",
       "   'V02HE02.png',\n",
       "   'V12HE02.png',\n",
       "   'V12HE03.png',\n",
       "   'V02HE03.png',\n",
       "   'V07HE03.png',\n",
       "   'V07HE02.png',\n",
       "   'V03HE2.png',\n",
       "   'V06HE03.png',\n",
       "   'V06HE02.png',\n",
       "   'V03HE3.png',\n",
       "   'V04HE03.png',\n",
       "   'V04HE02.png',\n",
       "   'V05HE03.png',\n",
       "   'V55HE09.png',\n",
       "   'V55HE08.png',\n",
       "   'V05HE02.png']],\n",
       " ['/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset-parkinson/spiral/training/parkinson',\n",
       "  ['V09PE03.png',\n",
       "   'V10PE01.png',\n",
       "   'V09PE02.png',\n",
       "   'V10PE02.png',\n",
       "   'V01PE03.png',\n",
       "   'V01PE02.png',\n",
       "   'V11PE02.png',\n",
       "   'V08PE03.png',\n",
       "   'V11PE01.png',\n",
       "   'V08PE02.png',\n",
       "   'V03PE03.png',\n",
       "   'V13PE03.png',\n",
       "   'V13PE02.png',\n",
       "   'V03PE02.png',\n",
       "   'V13PE01.png',\n",
       "   'V03PE05.png',\n",
       "   'V12PE01.png',\n",
       "   'V12PE03.png',\n",
       "   'V02PE03.png',\n",
       "   'V03PE06.png',\n",
       "   'V02PE02.png',\n",
       "   'V12PE02.png',\n",
       "   'V07PE02.png',\n",
       "   'V07PE03.png',\n",
       "   'V03PE09.png',\n",
       "   'V03PE08.png',\n",
       "   'V06PE02.png',\n",
       "   'V06PE03.png',\n",
       "   'V14PE01.png',\n",
       "   'V14PE02.png',\n",
       "   'V04PE02.png',\n",
       "   'V04PE03.png',\n",
       "   'V05PE02.png',\n",
       "   'V15PE02.png',\n",
       "   'V15PE03.png',\n",
       "   'V05PE03.png']],\n",
       " ['/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset-parkinson/spiral/testing/healthy',\n",
       "  ['V55HE12.png',\n",
       "   'V10HE01.png',\n",
       "   'V55HE13.png',\n",
       "   'V09HE01.png',\n",
       "   'V08HE01.png',\n",
       "   'V55HE14.png',\n",
       "   'V55HE15.png',\n",
       "   'V11HE01.png',\n",
       "   'V01HE01.png',\n",
       "   'V02HE01.png',\n",
       "   'V07HE01.png',\n",
       "   'V03HE1.png',\n",
       "   'V06HE01.png',\n",
       "   'V04HE01.png',\n",
       "   'V05HE01.png']],\n",
       " ['/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset-parkinson/spiral/testing/parkinson',\n",
       "  ['V10PE03.png',\n",
       "   'V09PE01.png',\n",
       "   'V11PE03.png',\n",
       "   'V08PE01.png',\n",
       "   'V01PE01.png',\n",
       "   'V03PE01.png',\n",
       "   'V03PE04.png',\n",
       "   'V02PE01.png',\n",
       "   'V03PE07.png',\n",
       "   'V07PE01.png',\n",
       "   'V06PE01.png',\n",
       "   'V04PE01.png',\n",
       "   'V14PE03.png',\n",
       "   'V15PE01.png',\n",
       "   'V05PE01.png']]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to load the images. In a first step, let us load only **a single image** and prepare it. Then you can make a loop to deal with all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = N[0][0] + \"/\" + N[0][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `imread()` function from [OpenCV](https://pypi.org/project/opencv-python/) to process the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (46.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 46.4 MB 846 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(path_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is loaded as a numpy ndarray. It has 3 dimensions:\n",
    "\n",
    "- width\n",
    "- height\n",
    "- colour: Red, Green, and Blue (RGB) components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will then perform a principal component analysis (PCA) on the pixel values of each image. The main components will then be used as explanatory variables (features) to train a binary classifier to detect whether the drawings come from a healthy person or a person with Parkison’s disease. But you are facing a problem at this stage. PCA is an orthogonal linear transformation, and the data consists of triplet for each pixel, indicating the red, green and blue components (RGB). A simple way to get around this problem is to convert the image to grey scale, _i.e._, by calculating the average of the three RGB components. This is what the `cvtColor()` function from {cv2} does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images in this dataset are not all exactly the same size. Most of them are squares of 256 x 256 pixels. For the few exceptions, the difference is minimal. But for those, you need to resise the images.\n",
    "\n",
    "If interpolation is needed, you can use the nearest neighbours.\n",
    "\n",
    "Resize the image to 256 pixels x 256 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized = cv2.resize(image_gray, (256, 256), interpolation = cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[240, 239, 241, ..., 240, 244, 245],\n",
       "       [246, 243, 245, ..., 243, 235, 238],\n",
       "       [240, 244, 250, ..., 238, 236, 237],\n",
       "       ...,\n",
       "       [247, 234, 232, ..., 236, 237, 236],\n",
       "       [247, 237, 232, ..., 240, 231, 245],\n",
       "       [249, 242, 233, ..., 243, 235, 242]], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at our example.\n",
    "\n",
    "Plot your image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a loop over all files and apply the same pre-processing.\n",
    "\n",
    "For each example that you load, you must know whether it is from the training or the test sample (you can store this information on an array that you can call `sample`), and you must also know the true value (`healthy` or `parkinson`). To do so, from the path to the example that is being loaded, you can use the `seatch()` function from the `re` library and look for some pattern within the string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_sample_current = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/dataset-parkinson/spiral/testing/parkinson'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "type_example = []\n",
    "sample = []\n",
    "for i_folder in range(len(N)):\n",
    "    path_folder = N[i_folder][0]\n",
    "    for i_image in range(len((N[i_folder][1]))):\n",
    "        file_img = N[i_folder][1][i_image]\n",
    "        path_img = path_folder + '/'+ file_img\n",
    "        image = cv2.imread(path_img)\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_resized = cv2.resize(image_gray, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "        examples.append(image_resized)\n",
    "        \n",
    "        if bool(re.search(\"parkinson\", path_folder)):\n",
    "            type_example.append(\"parkinson\")\n",
    "        else:\n",
    "            type_example.appe,d(\"healthy\")\n",
    "\n",
    "        if bool(re.search(\"training\", path_folder)):\n",
    "            sample.append(\"training\")\n",
    "        else:\n",
    "            sample.append(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "type_example = []\n",
    "sample = []\n",
    "for i_folder in range(len(N)):\n",
    "    path_folder = N[i_folder][0]\n",
    "    for i_image in range(len(N[i_folder][1])):\n",
    "        file_img = N[i_folder][1][i_image]\n",
    "        path_img = path_folder+\"/\"+file_img\n",
    "        # Load the image\n",
    "        image = cv2.imread(path_img)\n",
    "        # Grey scale\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY )\n",
    "        # Resize\n",
    "        image_resized = cv2.resize(image_gray, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "        # Add the resized image to our train or test data\n",
    "        #examples.append(image_resized)\n",
    "        examples.append(image_resized.flatten())\n",
    "        # True answer: is it healty or parkinson?\n",
    "        if bool(re.search(\"parkinson\", path_folder)):\n",
    "            type_example.append(1)\n",
    "        else:\n",
    "            type_example.append(0)\n",
    "        # Type of sample: train or test\n",
    "        if bool(re.search(\"training\", path_folder)):\n",
    "            sample.append(\"training\")\n",
    "        else:\n",
    "            sample.append(\"testing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([240, 239, 241, ..., 243, 235, 242], dtype=uint8),\n",
       " array([244, 235, 240, ..., 244, 240, 238], dtype=uint8),\n",
       " array([242, 235, 235, ..., 234, 236, 232], dtype=uint8),\n",
       " array([242, 244, 241, ..., 238, 239, 238], dtype=uint8),\n",
       " array([238, 238, 246, ..., 236, 236, 239], dtype=uint8),\n",
       " array([235, 232, 233, ..., 236, 240, 239], dtype=uint8),\n",
       " array([240, 240, 227, ..., 236, 241, 240], dtype=uint8),\n",
       " array([230, 243, 243, ..., 243, 234, 233], dtype=uint8),\n",
       " array([237, 238, 236, ..., 230, 232, 232], dtype=uint8),\n",
       " array([234, 234, 231, ..., 218, 224, 235], dtype=uint8),\n",
       " array([243, 242, 243, ..., 227, 227, 234], dtype=uint8),\n",
       " array([237, 238, 239, ..., 241, 238, 243], dtype=uint8),\n",
       " array([231, 212, 253, ..., 246, 234, 236], dtype=uint8),\n",
       " array([233, 235, 227, ..., 232, 245, 238], dtype=uint8),\n",
       " array([237, 237, 239, ..., 230, 231, 235], dtype=uint8),\n",
       " array([242, 240, 239, ..., 237, 233, 242], dtype=uint8),\n",
       " array([241, 239, 237, ..., 236, 240, 236], dtype=uint8),\n",
       " array([238, 242, 238, ..., 237, 234, 234], dtype=uint8),\n",
       " array([237, 236, 237, ..., 226, 223, 233], dtype=uint8),\n",
       " array([238, 237, 240, ..., 234, 231, 227], dtype=uint8),\n",
       " array([245, 244, 246, ..., 246, 238, 231], dtype=uint8),\n",
       " array([248, 235, 244, ..., 235, 242, 245], dtype=uint8),\n",
       " array([247, 244, 234, ..., 236, 242, 244], dtype=uint8),\n",
       " array([240, 234, 232, ..., 229, 239, 241], dtype=uint8),\n",
       " array([243, 238, 241, ..., 233, 235, 236], dtype=uint8),\n",
       " array([244, 241, 242, ..., 226, 235, 241], dtype=uint8),\n",
       " array([240, 237, 243, ..., 229, 229, 243], dtype=uint8),\n",
       " array([246, 247, 238, ..., 245, 243, 247], dtype=uint8),\n",
       " array([236, 237, 240, ..., 239, 243, 237], dtype=uint8),\n",
       " array([237, 242, 236, ..., 237, 235, 238], dtype=uint8),\n",
       " array([248, 241, 239, ..., 242, 240, 235], dtype=uint8),\n",
       " array([236, 233, 242, ..., 240, 240, 239], dtype=uint8),\n",
       " array([245, 242, 239, ..., 241, 235, 238], dtype=uint8),\n",
       " array([216, 239, 229, ..., 224, 225, 220], dtype=uint8),\n",
       " array([240, 240, 235, ..., 241, 240, 238], dtype=uint8),\n",
       " array([236, 239, 243, ..., 235, 237, 243], dtype=uint8),\n",
       " array([241, 238, 239, ..., 235, 234, 242], dtype=uint8),\n",
       " array([243, 245, 237, ..., 237, 239, 241], dtype=uint8),\n",
       " array([238, 229, 237, ..., 241, 238, 237], dtype=uint8),\n",
       " array([238, 243, 240, ..., 239, 237, 243], dtype=uint8),\n",
       " array([235, 230, 235, ..., 237, 229, 228], dtype=uint8),\n",
       " array([236, 232, 230, ..., 236, 231, 237], dtype=uint8),\n",
       " array([241, 244, 241, ..., 240, 240, 241], dtype=uint8),\n",
       " array([236, 234, 239, ..., 241, 226, 234], dtype=uint8),\n",
       " array([237, 240, 241, ..., 233, 230, 233], dtype=uint8),\n",
       " array([238, 231, 241, ..., 239, 237, 232], dtype=uint8),\n",
       " array([240, 240, 240, ..., 238, 240, 229], dtype=uint8),\n",
       " array([243, 239, 243, ..., 234, 237, 238], dtype=uint8),\n",
       " array([239, 240, 239, ..., 238, 242, 239], dtype=uint8),\n",
       " array([239, 242, 240, ..., 229, 227, 228], dtype=uint8),\n",
       " array([242, 240, 235, ..., 239, 234, 230], dtype=uint8),\n",
       " array([235, 242, 246, ..., 240, 244, 243], dtype=uint8),\n",
       " array([242, 233, 230, ..., 238, 237, 238], dtype=uint8),\n",
       " array([243, 249, 233, ..., 245, 239, 226], dtype=uint8),\n",
       " array([236, 231, 237, ..., 242, 226, 222], dtype=uint8),\n",
       " array([235, 241, 243, ..., 237, 232, 235], dtype=uint8),\n",
       " array([239, 245, 241, ..., 240, 235, 232], dtype=uint8),\n",
       " array([235, 241, 246, ..., 237, 234, 231], dtype=uint8),\n",
       " array([236, 237, 241, ..., 242, 234, 241], dtype=uint8),\n",
       " array([247, 241, 237, ..., 232, 223, 246], dtype=uint8),\n",
       " array([227, 232, 234, ..., 217, 227, 226], dtype=uint8),\n",
       " array([237, 243, 245, ..., 244, 234, 237], dtype=uint8),\n",
       " array([243, 234, 237, ..., 231, 232, 235], dtype=uint8),\n",
       " array([235, 230, 236, ..., 235, 241, 241], dtype=uint8),\n",
       " array([241, 253, 251, ..., 233, 240, 254], dtype=uint8),\n",
       " array([249, 247, 247, ..., 239, 242, 248], dtype=uint8),\n",
       " array([240, 240, 237, ..., 240, 238, 243], dtype=uint8),\n",
       " array([232, 237, 244, ..., 239, 237, 242], dtype=uint8),\n",
       " array([253, 249, 243, ..., 241, 230, 229], dtype=uint8),\n",
       " array([236, 243, 238, ..., 244, 245, 248], dtype=uint8),\n",
       " array([240, 246, 254, ..., 237, 229, 238], dtype=uint8),\n",
       " array([236, 226, 226, ..., 230, 231, 243], dtype=uint8),\n",
       " array([235, 236, 230, ..., 230, 228, 233], dtype=uint8),\n",
       " array([243, 246, 242, ..., 235, 239, 238], dtype=uint8),\n",
       " array([235, 238, 236, ..., 247, 228, 235], dtype=uint8),\n",
       " array([245, 242, 239, ..., 238, 238, 240], dtype=uint8),\n",
       " array([248, 240, 239, ..., 237, 242, 237], dtype=uint8),\n",
       " array([236, 237, 235, ..., 235, 228, 236], dtype=uint8),\n",
       " array([229, 226, 237, ..., 237, 234, 237], dtype=uint8),\n",
       " array([238, 229, 229, ..., 243, 245, 240], dtype=uint8),\n",
       " array([242, 236, 237, ..., 234, 234, 235], dtype=uint8),\n",
       " array([253, 241, 246, ..., 255, 248, 243], dtype=uint8),\n",
       " array([239, 240, 242, ..., 228, 235, 237], dtype=uint8),\n",
       " array([239, 246, 241, ..., 243, 237, 234], dtype=uint8),\n",
       " array([240, 238, 244, ..., 244, 239, 235], dtype=uint8),\n",
       " array([244, 241, 237, ..., 230, 231, 238], dtype=uint8),\n",
       " array([246, 242, 242, ..., 231, 230, 237], dtype=uint8),\n",
       " array([232, 231, 241, ..., 236, 230, 237], dtype=uint8),\n",
       " array([247, 244, 235, ..., 234, 233, 229], dtype=uint8),\n",
       " array([236, 231, 234, ..., 233, 230, 229], dtype=uint8),\n",
       " array([242, 248, 246, ..., 246, 242, 239], dtype=uint8),\n",
       " array([239, 239, 239, ..., 238, 239, 235], dtype=uint8),\n",
       " array([239, 242, 238, ..., 235, 230, 237], dtype=uint8),\n",
       " array([235, 240, 242, ..., 235, 230, 236], dtype=uint8),\n",
       " array([210, 222, 240, ..., 243, 240, 240], dtype=uint8),\n",
       " array([240, 242, 241, ..., 237, 240, 239], dtype=uint8),\n",
       " array([240, 240, 237, ..., 235, 225, 224], dtype=uint8),\n",
       " array([239, 223, 220, ..., 236, 227, 228], dtype=uint8),\n",
       " array([239, 237, 237, ..., 239, 236, 238], dtype=uint8),\n",
       " array([249, 247, 248, ..., 246, 244, 236], dtype=uint8),\n",
       " array([247, 237, 236, ..., 247, 251, 246], dtype=uint8),\n",
       " array([232, 239, 242, ..., 227, 228, 241], dtype=uint8)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using PCA, you need to rescale the data so that the range of the values lie in the [0,1] interval. To that end, you can use a minmax scaler.\n",
    "\n",
    "$x_{i, \\text{scaled}} = \\frac{x_i-min(x_i)}{max(x_i) - min(x_i)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_scaled = scaler.fit_transform(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69767442, 0.65853659, 0.61764706, ..., 0.68421053, 0.42857143,\n",
       "        0.64705882],\n",
       "       [0.79069767, 0.56097561, 0.58823529, ..., 0.71052632, 0.60714286,\n",
       "        0.52941176],\n",
       "       [0.74418605, 0.56097561, 0.44117647, ..., 0.44736842, 0.46428571,\n",
       "        0.35294118],\n",
       "       ...,\n",
       "       [0.90697674, 0.85365854, 0.82352941, ..., 0.76315789, 0.75      ,\n",
       "        0.47058824],\n",
       "       [0.86046512, 0.6097561 , 0.47058824, ..., 0.78947368, 1.        ,\n",
       "        0.76470588],\n",
       "       [0.51162791, 0.65853659, 0.64705882, ..., 0.26315789, 0.17857143,\n",
       "        0.61764706]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create your training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_training = np.array(sample) == \"training\"\n",
    "y_train = np.array(type_example)[mask_training]\n",
    "y_test = np.array(type_example)[np.logical_not(mask_training)]\n",
    "\n",
    "X_train = np.array(examples_scaled)[mask_training]\n",
    "X_test = y_test = np.array(examples_scaled)[np.logical_not(mask_training)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72,), (72, 65536))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 65536), (30, 65536))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, you can perform a principal component analysis on the pixel values to extract the first components that can then be used to train the classifier. To do so, you give the matrix containing our training observations to the `PCA()` function from the module `decomposition` of the library `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuma that you want to extract only the first three components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on `X_train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components are returned in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can apply the dimensionality reduction on the data, using the `transform()` function from `pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.55923334e-03,  5.22367370e-04,  4.77874173e-05, ...,\n",
       "        -9.27882410e-04,  7.95349540e-04,  2.64870074e-03],\n",
       "       [ 2.52142737e-03,  6.08967567e-03,  6.40812905e-03, ...,\n",
       "         1.33130338e-03,  4.70842376e-03,  8.11910280e-03],\n",
       "       [ 6.29549551e-03,  6.15010792e-03,  4.09731614e-03, ...,\n",
       "         3.29736046e-03,  1.64773618e-03,  4.80304806e-03]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced =  pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.08612302e+00,  4.53233419e+00,  7.96695841e+00],\n",
       "       [-3.67470562e+00,  1.12870077e+00,  1.22472602e+00],\n",
       "       [ 4.52382859e+00, -1.11545024e+00, -7.26825657e+00],\n",
       "       [-8.79092874e+00,  4.10209341e+00,  5.73817688e+00],\n",
       "       [-1.00743634e+00, -1.74901167e+00, -3.45302666e+00],\n",
       "       [-1.06123612e+00, -2.38362932e+00, -1.99570772e+00],\n",
       "       [-1.15986619e+00, -4.14112613e-01,  5.56216646e-01],\n",
       "       [ 1.38692211e+00, -3.61344056e+00, -3.53131628e+00],\n",
       "       [-2.78180228e+00,  1.26059404e-01,  5.21861957e-01],\n",
       "       [-9.05726722e-01, -7.17666391e+00,  3.02315706e+00],\n",
       "       [ 3.13035926e-01, -4.21422391e+00,  1.14328968e+01],\n",
       "       [ 3.51337227e+00,  2.42057891e+00, -4.68935532e+00],\n",
       "       [-3.38117008e+00,  6.11744684e-01, -2.32919980e-01],\n",
       "       [ 8.36250022e+00, -5.28616924e+00, -1.52789683e+01],\n",
       "       [-9.79849330e-01, -3.19943152e+00, -3.10419628e+00],\n",
       "       [-2.57747617e-01, -9.89891305e-01,  1.35101000e+00],\n",
       "       [-1.15143798e+00, -1.60134860e-01, -2.73238141e+00],\n",
       "       [-8.53488332e-01, -1.69687324e+00, -1.40324430e-01],\n",
       "       [-3.92070660e-01, -3.47573951e+00, -2.23833325e+00],\n",
       "       [ 1.16906972e+00, -1.91562981e+00, -8.65157493e-01],\n",
       "       [-6.34484032e+00,  4.78659298e+00,  1.44847020e+01],\n",
       "       [-5.38346657e+00,  2.61654820e+00,  4.34617159e+00],\n",
       "       [-7.73960535e+00,  3.82744051e+00,  6.60501864e+00],\n",
       "       [-5.28835703e+00,  1.74590910e+00,  1.17489550e+00],\n",
       "       [ 1.79118709e+00, -1.10442718e+00,  1.56471063e+00],\n",
       "       [-5.27821728e-01,  1.99848006e+00, -1.62543605e+00],\n",
       "       [-2.26028714e-01, -3.42860299e+00,  6.98897100e-01],\n",
       "       [-7.39704969e+00,  5.61136568e+00,  1.07110212e+01],\n",
       "       [-3.04801102e-01,  8.10655938e-01,  2.28476101e-01],\n",
       "       [ 2.34071428e+00, -2.69870604e+00, -5.89385841e+00],\n",
       "       [-1.15106846e+00,  1.11718523e+00, -1.65033090e+00],\n",
       "       [ 4.22452130e+00, -3.35513206e+00, -9.70355325e+00],\n",
       "       [-2.56296249e+00,  2.41262987e+00,  2.90168370e+00],\n",
       "       [-3.63604883e+00, -1.80183699e+00,  5.10615578e-01],\n",
       "       [ 2.31086480e+00, -5.04387202e+00, -7.26800852e+00],\n",
       "       [-4.45881421e+00,  1.38979965e+00,  1.62232947e+00],\n",
       "       [-3.77021986e+00,  1.36877045e+00, -1.19304331e+00],\n",
       "       [ 4.59220981e+00, -5.68310797e+00, -6.88510393e+00],\n",
       "       [-1.44671165e+00, -1.31782786e+00,  2.52975519e+00],\n",
       "       [ 2.93011338e-01,  6.64678137e-01, -5.67498899e+00],\n",
       "       [ 8.63672115e+00, -1.11001943e+00, -9.38352799e+00],\n",
       "       [ 1.84232060e+00, -3.89779693e+00, -6.94814281e+00],\n",
       "       [-1.65465613e-01, -8.79924858e-01,  2.55898769e+00],\n",
       "       [ 2.68572472e+00, -2.96456320e+00, -6.13812837e+00],\n",
       "       [ 9.45761393e-01, -4.05400515e+00, -7.31922091e+00],\n",
       "       [ 3.82667678e+00, -5.58988756e+00, -5.69271457e+00],\n",
       "       [-3.14724593e+00,  1.84974105e-01,  1.33280327e+00],\n",
       "       [-2.71324827e-01, -2.44801022e+00, -4.63965381e+00],\n",
       "       [-3.19720423e+00,  2.97670002e+00,  8.60513625e-01],\n",
       "       [ 6.83666541e-01, -1.69125276e+00, -1.45874836e+00],\n",
       "       [-1.74629750e+00, -1.90446241e+00, -1.72983069e+00],\n",
       "       [-6.43024040e+00,  3.04085287e+00,  4.37233660e+00],\n",
       "       [-6.47352199e+00,  1.75234628e+00,  2.67592500e+00],\n",
       "       [-5.79596338e+00,  1.07789499e+00,  3.33690726e+00],\n",
       "       [ 2.97103738e-01, -3.42228699e+00,  2.37181077e-01],\n",
       "       [-3.36248404e+00,  9.24518933e-02,  2.46517888e+00],\n",
       "       [ 4.07215411e+00,  3.12048374e+00, -3.90879588e-01],\n",
       "       [-7.70069142e+00,  1.79656088e+00,  2.66037710e+00],\n",
       "       [-7.92674661e+00,  3.20548840e+00,  3.07843669e+00],\n",
       "       [-9.81799404e+00,  3.44628478e+00,  9.68951465e+00],\n",
       "       [ 1.36846896e+00, -4.79742780e+00, -4.49875526e+00],\n",
       "       [-5.41087552e+00,  2.76938571e+00,  3.08098200e+00],\n",
       "       [ 2.07285447e+00, -4.67861695e+00, -1.17027246e+01],\n",
       "       [-1.32674777e+00, -1.85912269e+00, -4.74517218e+00],\n",
       "       [ 3.29468785e+01,  5.98826967e+01, -2.23043196e+00],\n",
       "       [-1.01771292e+01,  4.21320855e+00,  2.49846455e+01],\n",
       "       [ 5.72039181e+01, -2.45527549e+01,  2.91589596e+01],\n",
       "       [ 1.18775970e+01, -2.62657761e+00, -2.24646676e+01],\n",
       "       [-3.12892260e+00, -3.04130125e-01,  2.14225016e+00],\n",
       "       [-1.16673418e+00,  2.73719766e-02,  7.52167264e-01],\n",
       "       [-4.97552157e-01, -1.00156411e+00,  3.27997500e+00],\n",
       "       [ 1.83442924e-01,  7.48050421e-01, -1.09355615e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the reduced training set:  (72, 3)\n",
      "Dimension of the reduced testing set:  (30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the reduced training set: \", X_train_reduced.shape)\n",
    "print(\"Dimension of the reduced testing set: \", X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "\n",
    "In this section you will train a classifier to recognize from the drawings of the subjects whether or not they have Parkinson's disease. To start slowly, you will put in place an example in which you will only retain the first three main components from the PCA that was conducted previously. The strategy you will use is as follows:\n",
    "\n",
    "- create the data table that will be used to train the classifier\n",
    "- train the classifier with a logistic regression (`LogisticRegression()`)\n",
    "- measure the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/Spiral_empty.ipynb Cell 59'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lilyhuong/Desktop/Amse%20mag3/Machine%20learning%20statistics/Spiral_empty.ipynb#ch0000049?line=0'>1</a>\u001b[0m reg_logit \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train_reduced, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1554\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1551'>1552</a>\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1552'>1553</a>\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1553'>1554</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1554'>1555</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1555'>1556</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1556'>1557</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1557'>1558</a>\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1558'>1559</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1560'>1561</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py?line=1561'>1562</a>\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "reg_logit = LogisticRegression(random_state=0).fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted values for both samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lilyhuong/Desktop/Amse mag3/Machine learning statistics/Spiral_empty.ipynb Cell 61'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lilyhuong/Desktop/Amse%20mag3/Machine%20learning%20statistics/Spiral_empty.ipynb#ch0000051?line=0'>1</a>\u001b[0m y_pred_train \u001b[39m=\u001b[39m reg_logit(X_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lilyhuong/Desktop/Amse%20mag3/Machine%20learning%20statistics/Spiral_empty.ipynb#ch0000051?line=1'>2</a>\u001b[0m y_pred_test \u001b[39m=\u001b[39m reg_logit(X_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LogisticRegression' object is not callable"
     ]
    }
   ],
   "source": [
    "y_pred_train = reg_logit(X_train)\n",
    "y_pred_test = reg_logit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix for the training sample:\n",
    "\n",
    "- in rows: true label\n",
    "- in columns: predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `classification_report()` function from `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **precision**: ability of the classifier not to label as positive a sample that is negative $\\frac{TP}{TP+FP}$\n",
    "- **recall**: ability of the classifier to find all the positive samples, true positive rate $\\frac{TP}{TP+FN}$\n",
    "- **f1-score**: harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the training sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And on the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over the number of components to use\n",
    "\n",
    "The higher the number of principal components used, the closer the projected data are from the initial dataset. Create a loop over M to try to know how many components seem to be enough to represent correctly the data.\n",
    "\n",
    "You can select M depending on the percentage of the cumulative variance that is explained.\n",
    "\n",
    "But fitst, go back to your example with M=3 components kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance explained by each dimension is returned in the `explained_variance_ratio_` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know the cumulative variance explained by the first dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the value of the number of components to 70:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the PCA with 70 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the attribute `explained_variance_ratio_` in your model objetc, compute the cumulative variance explained by the first dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_variance = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(range(1,M+1), cumsum_variance*100)\n",
    "plt.title(\"Percentage of variance explained as a function of the number of dimensions used\")\n",
    "plt.xlabel(\"Number of principal components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve (using a code, not setting the value by hand) the number of components needed so that the variance explained by the dimensions is at least 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify to the argument `n_components` `PCA()` the deisired percentage of explained variance you wish. The number of components kept is then based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform CPA with this number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `transform()` method, apply the reduction to your train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = \n",
    "X_test_reduced = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, fit a logistic model on the reduced train data to predict whether the patient has the parkinson disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_logit = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your estimated model to get the predictions on the train and on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = \n",
    "y_pred_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the confusion matrix on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_train = \n",
    "cf_matrix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, some code to visualize this matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
    "cf_matrix = cf_matrix_train\n",
    "cf_names = [\"True Neg.\", \"False Pos.\", \"False Neg.\", \"True Pos.\"]\n",
    "cf_n = [\"{0:0.0f}\".format(val) for val in cf_matrix.flatten()]\n",
    "cf_pct = [\"{0:.2%}\".format(val) for val in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "cf_labels = [f\"{val_1}\\n{val_2}\\n{val_3}\" for val_1, val_2, val_3 in zip(cf_names,cf_n,cf_pct)]\n",
    "cf_labels = np.asarray(cf_labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=cf_labels, \n",
    "            fmt='', cmap='Blues')\n",
    "ax.set_title(\"Confusion matrix, training test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_test = \n",
    "cf_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = cf_matrix_test\n",
    "cf_names = [\"True Neg.\", \"False Pos.\", \"False Neg.\", \"True Pos.\"]\n",
    "cf_n = [\"{0:0.0f}\".format(val) for val in cf_matrix.flatten()]\n",
    "cf_pct = [\"{0:.2%}\".format(val) for val in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "cf_labels = [f\"{val_1}\\n{val_2}\\n{val_3}\" for val_1, val_2, val_3 in zip(cf_names,cf_n,cf_pct)]\n",
    "cf_labels = np.asarray(cf_labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=cf_labels, \n",
    "            fmt='', cmap='Blues')\n",
    "ax.set_title(\"Confusion matrix, testing test\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
